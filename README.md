# Credit Card Fraud Detection

!()

Introduction Goes Here

### The Credit Card Fraud Dataset

The [Credit Card Fraud Detection dataset](https://www.kaggle.com/mlg-ulb/creditcardfraud) from Kaggle contains 284,807 credit card transactions made in September 2013 by credit cardholders.  Of the 284,807 transactions, 492 (0.172%) are fraudulent.  The dataset consists of 31 columns of numerical data.  Three of the columns are time (number of seconds between the first transaction in the dataset and the current transaction), amount of transaction, and class (1 = fraudulent; 0 = not fraudulent).  The remaining columns are designated as V1, V2, etc.  The variables in these columns were obtained using Principal Component Analysis (PCA) to transform data about each transaction.  We do not know what the original data features are because that information is confidential.

### Creating the Best Machine Learning Model

We used Amazon SageMaker Autopilot to select and build the best machine learning (ML) models for the credit card fraud dataset.  Autopilot, as the name suggests, automates the data preprocessing and model selectiong, building, and tuning.  We modeled our code on that in the GitHub repository [Direct Marketing with Amazon SageMaker AutoPilot](https://github.com/aws/amazon-sagemaker-examples/blob/master/autopilot/sagemaker_autopilot_direct_marketing.ipynb).  We ran two instances of Autopilot.  For the first, we accepted the default inputs and let Autopilot select the best type of model and metric for our data.  Autopilot correctly selected binary classification for the model type and selected F1 score for the metric used to measure which model would be best.  Since our dataset is imbalanced, we wanted to run another instance of Autopilot using Area Under the Curve (AUC) as the metric.  

In both notebooks, the code creates an Amazon S3 bucket for the ZIP file containing the credit card fraud data CSV file.  Then it splits the data into training and testing sets and uploads them to the Amazon S3 bucket.  Next the code configures and launches an Autopilot job to process the data, create a valdiation set, determine which five ML models would work best for the dataset.  Autopilot tunes the top models to determine the optimal hyperparameters.  

After the Autopilot job completes, the code deploys an inference pipeline to create a model from the top candidate returned by Autopilot.  It then uses batch transform to remove noise and other interferance that might affect model performance and generate predictions using the ML model.  Other candidate models can be viewed, and the location of two autogenerated notebooks, a Data Exploration Notebook and a Candidate Definition Notebook are given.  The final line of code cleans up the files created by Autopilot during processing

### Model Evaluation

For the model selected by Autopilot based on F1 score, the F1 score is X, accuracy is X, and the AUC is X.  For the model selected based on AUC, F1 score is 0.4532400071620941, accuracy is 0.9966800212860107, and the AUC is 0.9926300048828125.

### Resources

Amazon Web Serices. *AWS Deploy and Inference Pipeline*. https://docs.aws.amazon.com/sagemaker/latest/dg/inference-pipelines.html. Retrieved November 21, 2021.

Amazon Web Serices. *AWS Use Batch Transform*. https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html. Retrieved November 21, 2021.

Karpur, Ajay, et al. *Customer Churn Prediction with Amazon SageMaker Autopilot*. https://github.com/aws/amazon-sagemaker-examples/blob/master/autopilot/autopilot_customer_churn.ipynb. Retrieved November 22, 2021.

Samuel, James. *Training Models to Detect Credit Card Frauds with Amazon SageMaker Autopilot*. https://towardsdatascience.com/training-models-to-detect-credit-card-frauds-with-amazon-sagemaker-autopilot-d49a6b667b2e. Retrieved November 21, 2021.

Severtson, Roald Bradley, et al. *Direct Marketing with Amazon SageMaker AutoPilot*. https://github.com/aws/amazon-sagemaker-examples/blob/master/autopilot/sagemaker_autopilot_direct_marketing.ipynb. Retrieved November 21, 2021.
