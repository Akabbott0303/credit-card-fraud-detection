# Credit Card Fraud Detection

!()

Credit card fraud is a modern problem that affects everyone to some degree.  It costs card-issuing banks time, money, and human resources to track and resolve, and it costs consumers time and also money if fraudulent transactions are not caught.  It also shakes our sense of security.  Technology has evolved to create many machine learning models that can be used to detect credit card fraud.  Machine learning models can be built using code and data science libaries, and they can also be built using tools such as Amazon Web Services Autopilot program.  Amazon has a brand new tool called Canvas that makes building machine learning very easy even for non-programmers.

Which approach to building machine learning models to detect credit card fraud is best - a coding or non-coding approach?  Also, which type of model from the myriad choices available works the best?  These are the questions we set out to answer using a done-for-us dataset and several data science tools.

### The Credit Card Fraud Dataset

For our data, we used the famous [Credit Card Fraud Detection dataset](https://www.kaggle.com/mlg-ulb/creditcardfraud) from Kaggle.  This dataset contains 284,807 credit card transactions made in September 2013 by credit cardholders.  Of the 284,807 transactions, 492 (0.172%) are fraudulent.  

!(/Images/Target_Imbalance.PNG)

The dataset consists of 31 columns of numerical data.  Three of the columns are time (number of seconds between the first transaction in the dataset and the current transaction), amount of transaction, and class (1 = fraudulent; 0 = not fraudulent).  The remaining columns are designated as V1, V2, etc.  The variables in these columns were obtained using Principal Component Analysis (PCA) to transform data about each transaction.  We do not know what the original data features are because that information is confidential but we can see that several of the top 10 most predictive features are correlated with each other.

!(/Images/Correlation_Matrix.PNG)

### Creating the Best Machine Learning Model

We set out to discover what machine learning model might be the best for predicting credit card fraud in the real world.  We used several tools in the data science toolbox to find our best model.

#### Amazon SageMaker Autopilot

Our first step was to use Amazon SageMaker Autopilot to select and build several machine learning (ML) models for the credit card fraud dataset.  Autopilot, as the name suggests, automates the data preprocessing and model selectiong, building, and tuning.  We modeled our code on that in the GitHub repository [Direct Marketing with Amazon SageMaker AutoPilot](https://github.com/aws/amazon-sagemaker-examples/blob/master/autopilot/sagemaker_autopilot_direct_marketing.ipynb).  

We ran two instances of Autopilot.  For the first, we accepted the default inputs and let Autopilot select the best type of model and metric for our data.  Autopilot correctly selected binary classification for the model type and selected F1 score for the metric used to measure which model would be best.  

For imbalanced datasets like the credit card fraude dataset, the area under the Receiver Operating Characteristic (ROC) curve (AUC) is a better metric use. The AUC measures the true positive rate versus the false posictive rate to judege model performance.  For our second Autopilot instance, we used AUC as the defining metric.  

In both notebooks, the code creates an Amazon S3 bucket for the ZIP file containing the credit card fraud data CSV file.  Then it splits the data into training and testing sets and uploads them to the Amazon S3 bucket.  Next the code configures and launches an Autopilot job to process the data, create a valdiation set, determine which five ML models would work best for the dataset.  Autopilot tunes the top models to determine the optimal hyperparameters.  

After the Autopilot job completes, the code deploys an inference pipeline to create a model from the top candidate returned by Autopilot.  It then uses batch transform to remove noise and other interferance that might affect model performance and generate predictions using the ML model.  Other candidate models can be viewed, and the location of two autogenerated notebooks, a Data Exploration Notebook and a Candidate Definition Notebook are given.  The final line of code cleans up the files created by Autopilot during processing.

The Data Exploration Notebook gives an overview of the data.  We pulled our data exploration charts from this notebook.  The Candidate Defintion Notebook shows the code used by Autopilot for the top performing model, giving us an opportunity to further refine the model.

#### Home Grown Models

To see if Autopilot's model really is the best, we built five of our own models using the Scikit-Learn library:

1. Decision Tree
2. Gradient Boosting
3. Random Forest
4. Bagging Classifier
4. XGBoost

The Decision Tree is a supervised learning method.  In classification problems, it predicts target values by using the features of a dataset to make decisions.

The Gradient Boosting Classifier is an additive model that combines other models together to create one model that performs better than its parts.

The Random Forest Classifier is a meta estimator that creates several decision trees from sub-sets of data and averages the results of each to make predictions.

The Bagging Classifier is an ensemble meta estimator.  Like Random Forest, it uses sub-sets of the data.  The predictions from fitting classifiers on the data subsets are aggregated or averaged to generate model predictions.

XGBoost appears to be the current "it" model for classification problems.  This is the model AWS Autopilot selected as the best for the credit card fraud dataset.  XGBoost is "an implementation of gradient boosted decision trees designed for speed and performance" (Brownlee, *XGBoost*).

### Model Evaluation

As noted above, the area under the Receiver Operating Characteristic (ROC) curve (AUC) is the best metric to use for imbalanced datasets. The AUC measures the true positive rate versus the false posictive rate.  

AWS Autopilot calculated the AUC score as well as the F1 score and accuracy for its model as part of the code we used.

We used Scikit-Learn to return and plot the AUC score for all of our models.  We also printed the F1 score, classification report, and confusion matrix for all models.

For the model selected by Autopilot based on F1 score, the F1 score is 0.6461499929428101, accuracy is 0.9984899759292603, and the AUC is 0.9936299920082092.  For the model selected based on AUC, F1 score is 0.4532400071620941, accuracy is 0.9966800212860107, and the AUC is 0.9926300048828125.

### Conclusions



### Resources

Adithyan, Nikihil. *Credit Card Fraud Detection with Machine Learning in Python.* https://medium.com/codex/credit-card-fraud-detection-with-machine-learning-in-python-ac7281991d87. Retrieved 2 December 2021.

Amazon Web Serices. *AWS Deploy and Inference Pipeline*. https://docs.aws.amazon.com/sagemaker/latest/dg/inference-pipelines.html. Retrieved November 21, 2021.

Amazon Web Serices. *AWS Use Batch Transform*. https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html. Retrieved November 21, 2021.

Brownlee, Jason. *A Gentle Introduction to the Gradient Boosting Algorithm for Machine Learning.*. https://machinelearningmastery.com/gentle-introduction-gradient-boosting-algorithm-machine-learning/. Retrieved 3 December 2021.

Brownlee, Jason. *A Gentle Introduction to XGBoost for Applied Machine Learning.*. . Retrieved 3 December 2021.
https://machinelearningmastery.com/gentle-introduction-xgboost-applied-machine-learning/.

Brownlee, Jason. *Bagging and Random Forest for Imbalanced Classification*. https://machinelearningmastery.com/bagging-and-random-forest-for-imbalanced-classification/. Retrieved 2 December 2021.

Karpur, Ajay, et al. *Customer Churn Prediction with Amazon SageMaker Autopilot*. https://github.com/aws/amazon-sagemaker-examples/blob/master/autopilot/autopilot_customer_churn.ipynb. Retrieved November 22, 2021.

Samuel, James. *Training Models to Detect Credit Card Frauds with Amazon SageMaker Autopilot*. https://towardsdatascience.com/training-models-to-detect-credit-card-frauds-with-amazon-sagemaker-autopilot-d49a6b667b2e. Retrieved November 21, 2021.

Severtson, Roald Bradley, et al. *Direct Marketing with Amazon SageMaker AutoPilot*. https://github.com/aws/amazon-sagemaker-examples/blob/master/autopilot/sagemaker_autopilot_direct_marketing.ipynb. Retrieved November 21, 2021.

Sun, Luke.  *Credit Card Fraud Detection*. https://towardsdatascience.com/credit-card-fraud-detection-9bc8db79b956. Retrieved 2 December 2021.
